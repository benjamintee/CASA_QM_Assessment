---
date: last-modified
bibliography: References.bib
csl: harvard-cite-them-right.csl
title: CASA0007 Assessment Submission
execute:
  echo: false
  freeze: true
format:
  html:
    code-copy: true
    code-link: true
    toc: true
    toc-title: On this page
    toc-depth: 2
    toc_float:
      collapsed: false
      smooth_scroll: true
  pdf:
    include-in-header:
      text: |
        \addtokomafont{disposition}{\rmfamily}
    mainfont: "Source Serif 4"
    sansfont: "Source Sans 3"
    monofont: "Source Code Pro"
    papersize: a4
    geometry:
      - top=25mm
      - left=40mm
      - right=30mm
      - bottom=25mm
      - heightrounded
    toc: false
    number-sections: false
    colorlinks: true
    highlight-style: github
jupyter:
  jupytext:
    text_representation:
      extension: .qmd
      format_name: quarto
      format_version: '1.0'
      jupytext_version: 1.15.2
  kernelspec:
    display_name: Python 3 (ipykernel)
    language: python
    name: python3
---

## Declaration of Authorship {.unnumbered .unlisted}

I, Tee Chin Min Benjamin, pledge my honour that the work presented in this assessment is my own. Where information has been derived from other sources, I confirm that this has been indicated in the work. Where a Large Language Model such as ChatGPT has been used I confirm that we have made its contribution to the final submission clear.

Date: 12 January 2026 (Tues)

Student Number: 25049107

{{< pagebreak >}}

### Project Setup

```{python}
#| label: Load common libraries and packages
#| echo: false
#| warning: false
import pandas as pd
import geopandas as gpd
import numpy as np
import matplotlib.pyplot as plt
import matplotlib.ticker as ticker
from matplotlib.lines import Line2D
from pathlib import Path
import requests
import mapclassify
import math
from matplotlib.patches import Patch
from matplotlib.ticker import FuncFormatter
import os
import glob
import seaborn as sns
import scipy.stats as stats
from statsmodels.stats.outliers_influence import variance_inflation_factor
```

```{python}
#| label: Download BibTeX and csl files into the same folder if not been downloaded yet
#| echo: false
#| warning: false
#| output: false
# Name of the BibTeX and csl files
bib_name = ["References.bib", "harvard-cite-them-right.csl"]

# Folder where the .qmd file lives
qmd_folder = Path(".").resolve()  

# Raw GitHub URL
url_bib = "https://raw.githubusercontent.com/benjamintee/CASA_QM_Assessment/refs/heads/main/References.bib"

for bib in bib_name:
    # Full path for the BibTeX/csl file
    bib_path = qmd_folder / bib

    # Download only if missing
    if not bib_path.exists():
        print(f"{bib_name} not found. Downloading to {bib_path} ...")
        response = requests.get(url_bib)
        response.raise_for_status()
        bib_path.write_bytes(response.content)
        print("Download complete!")
    else:
        print(f"{bib_name} already exists at {bib_path}")
```

```{python}
#| label: Download EPC data and read into python
#| echo: false
#| warning: false

# Read EPC data and download the specific columns 
base = "large/"
cols = [
    "POSTCODE",
    "PROPERTY_TYPE",
    "BUILT_FORM",
    "CURRENT_ENERGY_EFFICIENCY",
    "CURRENT_ENERGY_RATING",
    "TOTAL_FLOOR_AREA",
    "MAINHEAT_DESCRIPTION",
    "TENURE",
    "LODGEMENT_DATE"]

# Identify the files in the folder ending with .csv 
files = sorted(glob.glob(os.path.join(base, "certificates_*.csv")))

epc_parts = []

# Read and compile the data 
for f in files:
    print(f"Reading {os.path.basename(f)}")

    df = pd.read_csv(
        f,
        usecols=cols,
        parse_dates=["LODGEMENT_DATE"],
        low_memory=False
    )

    epc_parts.append(df)

epc = pd.concat(epc_parts, ignore_index=True)

# Clean data and set appropriate format type 
epc["CURRENT_ENERGY_RATING"] = epc["CURRENT_ENERGY_RATING"].astype("category")
epc["PROPERTY_TYPE"] = epc["PROPERTY_TYPE"].astype("category")
epc["BUILT_FORM"] = epc["BUILT_FORM"].astype("category")
epc["TENURE"] = epc["TENURE"].astype("category")

# Load ONS directory to map postal codes to MSOA, LA  
ons_pd = pd.read_csv(
    base + "ONSPD_FEB_2024_UK.csv",
    encoding="cp1252",
    usecols=[
        "pcds",     # postcode
        "msoa21cd",   # MSOA code
        "msoa21nm",  # MSOA name
        "ladcd",     # local authority code
        "ladnm",     # local authority name
    ],
    low_memory=False)

ons_pd = ons_pd.rename(columns={"pcds": "POSTCODE"})
```

```{python}
#| label: Merge EPC data and aggregate at MSOA-Level 
#| echo: false
#| warning: false
# Merge with ONS_PD to obtain the postal mapping to MSOA and LA 
epc_msoa = epc.merge(
    ons_pd,
    on="POSTCODE",
    how="left")

# Count the number of NAs and overall match rate 
match_rate = epc_msoa["msoa21cd"].notna().mean()
print(f"Match rate: {match_rate:.2%}")
```

```{python}
#| label: Clean EPC data 
#| echo: false
#| warning: false
# Drop those without valid matches and report the drop rate 
epc_msoa_clean = epc_msoa.dropna(subset=["msoa21cd"]).copy()
retain_rate = len(epc_msoa_clean) / len(epc_msoa)

# Clean the tenure column 
epc_msoa_clean["TENURE_CLEAN"] = (
    epc_msoa_clean["TENURE"]
    .str.strip()
    .str.lower())

tenure_map = {
    "owner-occupied": "owner",
    "rented (private)": "private_rented",
    "rental (private)": "private_rented",
    "rented (social)": "social_rented",
    "rental (social)": "social_rented",
    "unknown": None,
    "not defined - use in the case of a new dwelling for which the intended tenure in not known. it is not to be used for an existing dwelling": None
}

epc_msoa_clean["TENURE_STD"] = epc_msoa_clean["TENURE_CLEAN"].map(tenure_map)

epc_msoa_clean["epc_DG"] = (
    epc_msoa_clean["CURRENT_ENERGY_RATING"]
    .isin(["D", "E", "F", "G"])
    .astype(int)
)
epc_msoa_clean["is_rented"] = epc_msoa_clean["TENURE_STD"].isin(
    ["private_rented", "social_rented"]
).astype("float")

# Aggregate EPC floor area to MSOA (median)
floor_area_msoa = (
    epc_msoa_clean
    .groupby("msoa21cd")
    .agg(
        median_floor_area_m2=("TOTAL_FLOOR_AREA", "median"),
        n_epcs_area=("TOTAL_FLOOR_AREA", "count")
    )
    .reset_index()
)
```

```{python}
#| echo: false
#| warning: false
# Aggregate energy efficiency and share of EPC_DG for MSOAs
epc_msoa_agg = (
    epc_msoa_clean
    .groupby("msoa21cd")
    .agg(
        mean_epc_score=("CURRENT_ENERGY_EFFICIENCY", "mean"),
        share_epc_DG=("epc_DG", "mean"),
        median_floor_area_m2=("TOTAL_FLOOR_AREA", "median"),
        n_epcs=("CURRENT_ENERGY_EFFICIENCY", "count"),
        n_epcs_area=("TOTAL_FLOOR_AREA", "count"),
        share_rented=("is_rented", "mean"))
    .reset_index())

# Rename columns and align col names for merging - epc
epc_msoa_agg = epc_msoa_agg.rename(
    columns={"msoa21cd": "MSOA_code"}
)

# Filter for MSOAs within England only 
epc_msoa_agg = epc_msoa_agg.loc[
    lambda df: df["MSOA_code"].str.startswith("E")
]

# Cap the median floor area given some properties are very large 
upper_cap = epc_msoa_agg["median_floor_area_m2"].quantile(0.99)

epc_msoa_agg["median_floor_area_m2_capped"] = (
    epc_msoa_agg["median_floor_area_m2"]
    .clip(upper=upper_cap)
)
```

```{python}
#| echo: false
#| warning: false
# Read in domestic gas and electricty consumption data for 2023 
# Note: Median consumption was chosen as as it reflects a typical household’s gas use and is robust to outliers, comparable across MSOAs with different housing stocks and aligns directly with household energy burden
domestic_gas_msoa = pd.read_csv(
    r"data\MSOA_domestic_gas_2023.csv",
    encoding="cp1252",
    usecols=[
        "Local authority code",     
        "Local authority",   
        "MSOA code",  
        "Middle layer super output area",     
        "Number of meters", 
        "Median consumption (kWh per meter)",
    ],
    low_memory=False)

domestic_electricity_msoa = pd.read_csv(
    r"data\MSOA_domestic_elec_2023.csv",
    encoding="cp1252",
    usecols=[
        "Local authority code",     
        "Local authority",   
        "MSOA code",  
        "Middle layer super output area",     
        "Number of meters", 
        "Median consumption (kWh per meter)",
    ],
    low_memory=False)

# Rename columns and align col names for merging - Gas
domestic_gas_msoa = domestic_gas_msoa.rename(columns={
    "MSOA code": "MSOA_code",
    "Median consumption (kWh per meter)": "median_gas_kwh",
    "Number of meters": "n_gas_meters"
})

# Rename columns and align col names for merging - Electricity 
domestic_electricity_msoa = domestic_electricity_msoa.rename(columns={
    "MSOA code": "MSOA_code",
    "Median consumption (kWh per meter)": "median_elec_kwh",
    "Number of meters": "n_elec_meters"
})

for col in ["n_gas_meters", "median_gas_kwh"]:
    domestic_gas_msoa[col] = (
        domestic_gas_msoa[col]
        .astype(str)                 
        .str.replace(",", "", regex=False)  
        .str.strip()
        .replace({"": None, "–": None, "-": None})
        .pipe(pd.to_numeric, errors="coerce")
    )

for col in ["n_elec_meters", "median_elec_kwh"]:
    domestic_electricity_msoa[col] = (
        domestic_electricity_msoa[col]
        .astype(str)                 
        .str.replace(",", "", regex=False)  
        .str.strip()
        .replace({"": None, "–": None, "-": None})
        .pipe(pd.to_numeric, errors="coerce")
    )
```

```{python}
#| echo: false
#| warning: false
# Read in Census 2021 data on renewable energy usage for central heating 
heating = pd.read_csv(
    r"data/TS046_2021_Renewables.csv",
    usecols=[
        "Middle layer Super Output Areas Code",
        "Type of central heating in household (13 categories)",
        "Observation"])

# Rename columns and align col names for merging
heating = heating.rename(columns={
    "Middle layer Super Output Areas Code": "MSOA_code",
    "Type of central heating in household (13 categories)": "heating_type",
    "Observation": "n_households"
})

# Count number of total households in each MSOA for heating dataset
total_households = (
    heating
    .groupby("MSOA_code", as_index=False)["n_households"]
    .sum()
    .rename(columns={"n_households": "total_households"})
)

# Count number of households using renewable energy only in each MSOA for heating dataset
renewable_households = (
    heating
    .loc[heating["heating_type"] == "Renewable energy only"]
    .groupby("MSOA_code", as_index=False)["n_households"]
    .sum()
    .rename(columns={"n_households": "renewable_households"})
)

# Calculate renewable energy share in each MSOA 
renewable_share = (
    total_households
    .merge(renewable_households, on="MSOA_code", how="left"))

renewable_share["renewable_households"] = (
    renewable_share["renewable_households"].fillna(0))

renewable_share["share_renewable_heating"] = (
    renewable_share["renewable_households"] /
    renewable_share["total_households"])
```

```{python}
#| echo: false
#| warning: false
# Read in Census 2021 data on housing type
housing_type = pd.read_csv(
    r"data/TS046_2021_Renewables.csv",
    usecols=[
        "Middle layer Super Output Areas Code",
        "Type of central heating in household (13 categories)",
        "Observation"])
```

```{python}
#| echo: false
#| warning: false
# Read Census 2021 tenure data
tenure = pd.read_csv(
    r"data/TS044_2021_Housingtype.csv",
    usecols=[
        "Middle layer Super Output Areas Code",
        "Accommodation type (8 categories)",
        "Observation"
    ]
).rename(columns={
    "Middle layer Super Output Areas Code": "MSOA_code",
    "Accommodation type (8 categories)": "housing_type",
    "Observation": "n_households"
})

# Define housing_type groupings
detached_types = [
    "Detached"
]

house_types = [
    "Semi-detached",
    "Terraced"
]

flats_types = [
    "In a purpose-built block of flats or tenement"
]

nonstandard_types = [
    "Part of a converted or shared house, including bedsits",
    "Part of another converted building, for example, former school, church or warehouse",
    "In a commercial building, for example, in an office building, hotel or over a shop",
    "A caravan or other mobile or temporary structure"
]

# Aggregate in one pass
housing_shares = (
    tenure
    .assign(
        detached=lambda df: np.where(
            df["housing_type"].isin(detached_types),
            df["n_households"], 0
        ),
        houses=lambda df: np.where(
            df["housing_type"].isin(house_types),
            df["n_households"], 0
        ),
        flats=lambda df: np.where(
            df["housing_type"].isin(flats_types),
            df["n_households"], 0
        ),
        nonstandard=lambda df: np.where(
            df["housing_type"].isin(nonstandard_types),
            df["n_households"], 0
        )
    )
    .groupby("MSOA_code", as_index=False)
    .agg(
        total_households=("n_households", "sum"),
        detached=("detached", "sum"),
        houses=("houses", "sum"),
        flats=("flats", "sum"),
        nonstandard=("nonstandard", "sum")
    )
    .assign(
        share_detached=lambda df: df["detached"] / df["total_households"],
        share_houses=lambda df: df["houses"] / df["total_households"],
        share_flats_purpose_built=lambda df: df["flats"] / df["total_households"],
        share_nonstandard=lambda df: df["nonstandard"] / df["total_households"]
    )
    .loc[:, [
        "MSOA_code",
        "share_detached",
        "share_houses",
        "share_flats_purpose_built",
        "share_nonstandard"
    ]]
)
```

```{python}
#| echo: false
#| warning: false
# Read in annual household income data for 2023 
# Note: Household income is measured using equivalised disposable income after housing costs at MSOA level. This measure reflects the financial resources available to households after accounting for both taxes and unavoidable housing expenditures, making it appropriate for assessing vulnerability to energy costs.
income_msoa = pd.read_csv(
    r"data\MSOA_income_2023.csv",
    encoding="cp1252",
    usecols=[
        "Local authority code",     
        "Local authority name",   
        "MSOA code",  
        "MSOA name",     
        "Disposable (net) annual income after housing costs", 
    ],
    low_memory=False)

# Rename columns and align col names for merging - Income
income_msoa = income_msoa.rename(columns={
    "MSOA code": "MSOA_code",
    "Disposable (net) annual income after housing costs": "income_ahc"
})

for col in ["income_ahc"]:
    income_msoa[col] = (
        income_msoa[col]
        .astype(str)                 
        .str.replace(",", "", regex=False)  
        .str.strip()
        .replace({"": None, "–": None, "-": None})
        .pipe(pd.to_numeric, errors="coerce")
    )
```

```{python}
#| echo: false
#| warning: false
# Load MSOA → Region lookup
msoa_rgn = (
    pd.read_csv(r"data/MSOA_mapping_to_region.csv")
    .rename(columns={"MSOA21CD": "MSOA_code", "RGN22NM": "region"})
    [["MSOA_code", "region"]]
)

# Load MSOA → Rural or Urban lookup
msoa_rural = (
    pd.read_csv(r"data/MSOA_ruralurban.csv")
    .rename(columns={"MSOA21CD": "MSOA_code", "Rural Urban flag": "Ruralurban"})
    [["MSOA_code", "Ruralurban"]]
)
```

```{python}
#| echo: false
#| warning: false
# Load data on percentage of domestic properties not on gas grid 
msoa_gasgrid = (
    pd.read_csv(r"data/MSOA_domestic_notongasgrid.csv",
    encoding="cp1252",
    usecols=[
        "MSOA code",     
        "Middle layer super output area",   
        "Estimated percentage of properties not  on the gas grid"])
    .rename(columns={"MSOA code": "MSOA_code", "Estimated percentage of properties not  on the gas grid": "not_grid"})
    [["MSOA_code", "not_grid"]])

for col in ["not_grid"]:
    msoa_gasgrid[col] = (
        msoa_gasgrid[col]
        .astype(str)                 
        .str.replace("%", "", regex=False)  
        .str.strip()
        .replace({"": None, "–": None, "-": None})
        .pipe(pd.to_numeric, errors="coerce")
    )

msoa_gasgrid["share_not_grid"] = msoa_gasgrid["not_grid"] / 100
```

```{python}
#| echo: false
#| warning: false
# Aggregate by merging all the various datasets togerher 
msoa_agg = (
    epc_msoa_agg
    .merge(domestic_gas_msoa[["MSOA_code", "median_gas_kwh", "n_gas_meters"]],
           on="MSOA_code", how="left")
    .merge(domestic_electricity_msoa[["MSOA_code", "median_elec_kwh", "n_elec_meters"]],
           on="MSOA_code", how="left")
    .merge(income_msoa[["MSOA_code", "income_ahc"]],
           on="MSOA_code", how="left")
    .merge(tenure_share[["MSOA_code", "share_rented_census", "private_rented_census"]],
           on="MSOA_code", how="left")
    .merge(renewable_share[["MSOA_code", "share_renewable_heating"]],
           on="MSOA_code", how="left")
    .merge(housing_shares[["MSOA_code", "share_detached", "share_flats_purpose_built"]],
           on="MSOA_code", how="left")
    .merge(msoa_rgn[["MSOA_code", "region"]],
           on="MSOA_code", how="left")
    .merge(msoa_rural[["MSOA_code", "Ruralurban"]],
           on="MSOA_code", how="left")  
    .merge(msoa_gasgrid[["MSOA_code", "share_not_grid"]],
           on="MSOA_code", how="left")  
)
msoa_agg.isna().mean().sort_values()

msoa_agg = (
    msoa_agg
    .loc[
        (msoa_agg["n_gas_meters"] >= 30) &
        (msoa_agg["n_elec_meters"] >= 30)
    ]
)

# Referencing unit energy costs for gas and electricty from Ofgem.co.uk in Jan-Mar 2024, use GB average (including 5% VAT) under a standard credit assumption 

Elec_single_rate_nil = 219.30
Elec_single_rate_3100 = 1152.88
Elec_unit_rate = round((Elec_single_rate_3100 - Elec_single_rate_nil) / 3100, 2)

Gas_single_rate_nil = 127.64
Gas_single_rate_12000 = 1064.52
Gas_unit_rate = round((Gas_single_rate_12000 - Gas_single_rate_nil) / 12000, 2)

# Compute annual electricty and gas cost by multiplying consumption with the unit rate  
msoa_agg["annual_electricity_cost"] = msoa_agg["median_elec_kwh"] * Elec_unit_rate
msoa_agg["annual_gas_cost"] = msoa_agg["median_gas_kwh"] * Gas_unit_rate
msoa_agg["annual_energy_cost"] = (msoa_agg["annual_electricity_cost"] + msoa_agg["annual_gas_cost"]) + Elec_single_rate_nil + Gas_single_rate_nil 

# Compute Energy_burden metric as the ratio of annual_energy_cost to annual_household_income 
msoa_agg["energy_burden"] = msoa_agg["annual_energy_cost"] / msoa_agg["income_ahc"]

# Filter only those in England
msoa_agg = msoa_agg.loc[
    lambda df: df["MSOA_code"].str.startswith("E")]

msoa_agg["income_10k"] = msoa_agg["income_ahc"] / 10000
```

```{python}
#| echo: false
#| warning: false
# Load MSOA 2021 shapefile 
msoa_gdf = gpd.read_file(
    "large/MSOA/MSOA_2021_EW_BFE_V8.shp").to_crs(epsg=27700)

# Rename column to allow for effective matching between shapefile and msoa_agg
msoa_gdf = msoa_gdf.rename(columns={"MSOA21CD": "MSOA_code"})

# Aggregate data to shapefile
msoa_gdf_merged = (
    msoa_gdf
    .merge(msoa_agg, on="MSOA_code", how="left")) 

# Load Region Dec 2023 shapefile 
region_gdf = gpd.read_file(
    r"data\RGN_DEC_2023_EN_BFE.shp").to_crs(epsg=27700)

# Load Greater London Area Boundary 
gla = gpd.read_file("data/London_GLA_Boundary.shp").to_crs(epsg=27700)

# Load LA across GB and clip to GLA
LA = gpd.read_file("data/LAD_DEC_2021_GB_BUC.shp").to_crs(epsg=27700)
LA = gpd.overlay(LA, gla, how="intersection",
    keep_geom_type=False)

# Load Scottish Area Boundary 
scotland_gdf = gpd.read_file("data/Scotland boundary.shp").to_crs(epsg=27700)

# Get total bounds for England 
england_bounds = region_gdf.total_bounds

# Create clipping box slightly above England
from shapely.geometry import box

scot_bounds = scotland_gdf.total_bounds

clip_box = box(
    scot_bounds[0],              # minx of Scotland
    scot_bounds[1],              # miny of Scotland  
    scot_bounds[2],              # maxx of Scotland
    england_bounds[3] + 40000        # cap northward extent
)

scotland_clip = gpd.clip(scotland_gdf, clip_box)
```

```{python}
#| echo: false
#| warning: false
import pandas as pd
from shapely.geometry import Point

cities = pd.DataFrame({
    "city": [
        "London", "Birmingham", "Leeds", "Manchester", "Liverpool",
        "Sheffield", "Newcastle", "Southampton", "Hull", "Oxford",
        "Norwich", "Nottingham", "Plymouth"
    ],
    "x": [
        530000, 409000, 430000, 384000, 334000,
        435000, 424000, 442000, 509000, 451000,
        623000, 457000, 248000
    ],
    "y": [
        180000, 287000, 433000, 398000, 390000,
        387000, 565000, 113000, 432000, 206000,
        308000, 340000, 54000
    ]
})

cities_gdf = gpd.GeoDataFrame(
    cities,
    geometry=[Point(xy) for xy in zip(cities.x, cities.y)],
    crs="EPSG:27700"
)
```

### Data Analysis

```{python}
#| echo: false
#| warning: false
# Data Analysis - Understanding the distribution of the variables in the regression set 

reg_df = msoa_agg[
    ["energy_burden", "income_10k", "median_floor_area_m2_capped", "mean_epc_score", "share_epc_DG", "share_rented_census", "private_rented_census", "share_renewable_heating", "region", "Ruralurban", "share_not_grid"]
].dropna() 

reg_df = reg_df.copy()
reg_df["log_income"] = np.log(reg_df["income_10k"])

# Drop unwanted numeric columns
numeric_cols = reg_df.select_dtypes(include='number')

# Convert to long format
numeric_long = numeric_cols.melt(var_name='variable', value_name='value')

# Set up the figure
variables = numeric_long['variable'].unique()
n_vars = len(variables)
cols = 3
rows = (n_vars + cols - 1) // cols

fig, axes = plt.subplots(rows, cols, figsize=(9, 2 * rows))
axes = axes.flatten()

for i, var in enumerate(variables):
    sns.histplot(data=numeric_long[numeric_long['variable'] == var], x='value', kde=True, bins=30, color='steelblue', ax=axes[i])
    axes[i].set_title(var)
    axes[i].set_xlabel("Value")
    axes[i].set_ylabel("Count")

# Hide unused subplots
for j in range(i + 1, len(axes)):
    fig.delaxes(axes[j])

plt.tight_layout()
plt.suptitle("Histograms of Numerical Variables", y=1.02, fontsize = 14)
sns.despine()
plt.show()
```

```{python}
#| echo: false
#| warning: false
# Exploratory Analysis - Checking the relationships between the variables and energy burden 
# Select variables for plotting
plot_df = reg_df[
    [   "energy_burden",
        "log_income",
        "median_floor_area_m2_capped",
        "mean_epc_score",
        "share_epc_DG",
        "private_rented_census",
        "share_renewable_heating", 
         "share_not_grid"
    ]
].dropna()

# Convert to long format
long_df = pd.melt(
    plot_df,
    id_vars=["energy_burden"],
    var_name="predictor",
    value_name="x_value"
)

axis_labels = {
    "log_income": "Log Disposable income ('000) \naft housing costs)",
    "median_floor_area_m2_capped": "Median floor area (m²)",
    "mean_epc_score": "Mean EPC energy efficiency score",
    "share_epc_DG" : "Share of Buildings with EPC D-G",
    "private_rented_census": "Share of households \nprivate renting",
    "share_renewable_heating": "Share of households with \nrenewable-only heating",
    "share_not_grid": "Share of households \nnot on the gas grid"
}

predictors = long_df["predictor"].unique()

cols = 3
rows = (len(predictors) + cols - 1) // cols

fig, axes = plt.subplots(rows, cols, figsize=(9, 3 * rows))
axes = axes.flatten()

for i, predictor in enumerate(predictors):
    subset = long_df[long_df["predictor"] == predictor]

    sns.regplot(
        data=subset,
        x="x_value",
        y="energy_burden",
        scatter_kws={
            "alpha": 0.3,
            "s": 10,
            "color": "steelblue"
        },
        line_kws={
            "color": "black",
            "linewidth": 1.5
        },
        ci=None,
        ax=axes[i]
    )

    axes[i].set_title(f"Energy burden vs \n{axis_labels[predictor]}")
    axes[i].set_xlabel(axis_labels[predictor])
    axes[i].set_ylabel("Energy burden (share of income)")

# Remove unused axes
for j in range(i + 1, len(axes)):
    fig.delaxes(axes[j])

plt.tight_layout()
plt.suptitle(
    "Bivariate relationships between energy burden and key predictors",
    y=1.02,
    fontsize=14
)

sns.despine()
plt.show()
```

```{python}
#| echo: false
#| warning: false
from libpysal.weights import Queen
from esda.moran import Moran

w = Queen.from_dataframe(msoa_gdf_merged)
w.transform = "r"

mi = Moran(msoa_gdf_merged["energy_burden"].values, w)
mi.I, mi.p_sim
```

```{python}
import statsmodels.api as sm
from statsmodels.iolib.summary2 import summary_col 

# Model 1
X_1 = reg_df[["log_income", "share_epc_DG", "median_floor_area_m2_capped", "private_rented_census", "share_renewable_heating", "share_not_grid"]]
X_1 = sm.add_constant(X_1)

y = reg_df["energy_burden"]

model_1 = sm.OLS(y, X_1).fit(cov_type="HC1")  # robust SEs
print(model_1.summary())

results_table = summary_col(
    results=[model_1],
    model_names=['Base_Model'],
    stars=True,
    float_format="%0.3f",
    # You can customize what model statistics show up here (like R2, N, F-stat)
    info_dict={'N':lambda x: "{0:d}".format(int(x.nobs))}
)

# # Round for readability
print(results_table)
```

```{python}
#| echo: false
#| warning: false
# Next, we include regional dummies 
region_dummies = pd.get_dummies(
    reg_df["region"],
    prefix="region",
    drop_first=True)

# Model 2
X_2 = pd.concat([reg_df[["log_income", "share_epc_DG", "median_floor_area_m2_capped", "private_rented_census", "share_not_grid", "share_renewable_heating"]], region_dummies], axis = 1)
X_2 = sm.add_constant(X_2)
X_2 = X_2.astype(float)

y = reg_df["energy_burden"]

model_2 = sm.OLS(y, X_2).fit(cov_type="HC1")  # robust SEs
print(model_2.summary())

results_table = summary_col(
    results=[model_1, model_2],
    model_names=['Base_Model', "Regional Fixed Effects"],
    stars=True,
    float_format="%0.3f",
    # You can customize what model statistics show up here (like R2, N, F-stat)
    info_dict={'N':lambda x: "{0:d}".format(int(x.nobs))}
)

# # Round for readability
print(results_table)
```

```{python}
#| echo: false
#| warning: false
# Finally, we test if there is any significance of urban / rural effects
reg_df["urban_dummy"] = (
    reg_df["Ruralurban"]
    .map({"Urban": 1, "Rural": 0})
)

# Model 3
X_3 = pd.concat([reg_df[["log_income", "share_epc_DG", "median_floor_area_m2_capped", "private_rented_census", "share_renewable_heating", "share_not_grid", "urban_dummy"]], region_dummies], axis = 1)
X_3 = sm.add_constant(X_3)
X_3 = X_3.astype(float)

y = reg_df["energy_burden"]

model_3 = sm.OLS(y, X_3).fit(cov_type="HC1")  # robust SEs
print(model_3.summary())

results_table = summary_col(
    results=[model_1, model_2, model_3],
    model_names=['Base_Model', "Regional_FE", "Rural/Urban"],
    stars=True,
    float_format="%0.3f",
    # You can customize what model statistics show up here (like R2, N, F-stat)
    info_dict={'N':lambda x: "{0:d}".format(int(x.nobs))}
)

# # Round for readability
print(results_table)
```

```{python}
#| echo: false
#| warning: false
# Regression Diagnostics Check and Diagrams 

def plot_regression_diagnostics(model, X):
    """
    Diagnostics dashboard for OLS regression.
    Publication-ready layout with horizontal VIF plot and aligned titles.
    """
    import numpy as np
    import pandas as pd
    import seaborn as sns
    import matplotlib.pyplot as plt
    import scipy.stats as stats
    from statsmodels.stats.outliers_influence import variance_inflation_factor

    # -----------------------------
    # Core diagnostics quantities
    # -----------------------------
    fitted = model.fittedvalues
    resid = model.resid
    std_resid = model.get_influence().resid_studentized_internal
    sqrt_abs_std_resid = np.sqrt(np.abs(std_resid))

    # -----------------------------
    # VIF: compute with intercept,
    # display without intercept
    # -----------------------------
    X_full = X.astype(float)

    vif_all = pd.DataFrame({
        "Features": X_full.columns,
        "VIF Factor": [
            variance_inflation_factor(X_full.values, i)
            for i in range(X_full.shape[1])
        ]
    })

    vif_df = (
        vif_all
        .loc[vif_all["Features"] != "const"]
        .sort_values("VIF Factor")
        .reset_index(drop=True)
    )

    # Figure layout
    sns.set_style("whitegrid")
    fig = plt.figure(figsize=(12, 10))
    gs = fig.add_gridspec(3, 2, height_ratios=[1, 1, 0.8])

    # Helper for consistent titles
    def set_title_and_subtitle(ax, title, subtitle):
        ax.set_title(title, loc="left", fontsize=14, fontweight="bold", pad=18)
        ax.text(
            0, 1.01, subtitle,
            transform=ax.transAxes,
            fontsize=10,
            ha="left",
            va="bottom"
        )

    # ── 1. Linearity ─────────────────────────
    ax1 = fig.add_subplot(gs[0, 0])
    sns.scatterplot(x=fitted, y=resid, alpha=0.4, s=12, ax=ax1)
    sns.regplot(
        x=fitted, y=resid,
        scatter=False, lowess=True,
        line_kws={"color": "green"},
        ax=ax1
    )
    ax1.axhline(0, ls="--", color="black")
    set_title_and_subtitle(
        ax1,
        "Linearity",
        "Reference line should be flat and horizontal"
    )
    ax1.set_xlabel("Fitted values")
    ax1.set_ylabel("Residuals")

    # ── 2. Homoscedasticity ──────────────────
    ax2 = fig.add_subplot(gs[0, 1])
    sns.scatterplot(x=fitted, y=sqrt_abs_std_resid, alpha=0.4, s=12, ax=ax2)
    sns.regplot(
        x=fitted, y=sqrt_abs_std_resid,
        scatter=False, lowess=True,
        line_kws={"color": "green"},
        ax=ax2
    )
    set_title_and_subtitle(
        ax2,
        "Homogeneity of Variance",
        "Reference line should be flat and horizontal"
    )
    ax2.set_xlabel("Fitted values")
    ax2.set_ylabel(r"$\sqrt{|Std.\ residuals|}$")

    # ── 3. Collinearity (VIF – horizontal) ───
    ax3 = fig.add_subplot(gs[1, 0])

    # Sensible x-axis limit
    xmax = max(10, vif_df["VIF Factor"].max() + 0.5)

    # Background bands
    ax3.axvspan(0, 5, color="#2ecc71", alpha=0.15, zorder=0)
    ax3.axvspan(5, 10, color="#3498db", alpha=0.15, zorder=0)
    ax3.axvspan(10, xmax, color="#e74c3c", alpha=0.15, zorder=0)

    sns.scatterplot(
        data=vif_df,
        x="VIF Factor",
        y="Features",
        s=55,
        color="black",
        ax=ax3
    )

    ax3.axvline(5, ls="--", color="black", lw=1)
    ax3.axvline(10, ls="--", color="black", lw=1)

    ax3.set_xlim(0, xmax)
    ax3.set_xticks(range(0, int(xmax) + 1))

    set_title_and_subtitle(
        ax3,
        "Collinearity",
        "High collinearity (VIF) may inflate parameter uncertainty"
    )
    ax3.set_xlabel("Variance Inflation Factor (VIF)")
    ax3.set_ylabel("")
    ax3.tick_params(axis="y", labelsize=9)

    # ── 4. Normality (Q–Q deviation) ─────────
    ax4 = fig.add_subplot(gs[1, 1])
    n = len(std_resid)
    theoretical_q = stats.norm.ppf((np.arange(n) + 0.5) / n)
    sample_q = np.sort(std_resid)

    ax4.scatter(theoretical_q, sample_q - theoretical_q, s=12)
    ax4.axhline(0, color="green")
    set_title_and_subtitle(
        ax4,
        "Normality of Residuals",
        "Dots should fall along the line"
    )
    ax4.set_xlabel("Standard Normal Distribution Quantiles")
    ax4.set_ylabel("Sample Quantile Deviations")

    # ── 5. Residual density (bottom-left only) ─
    ax5 = fig.add_subplot(gs[2, 0])
    sns.kdeplot(resid, fill=True, alpha=0.3, ax=ax5)
    set_title_and_subtitle(
        ax5,
        "Residual Distribution",
        "Distribution should be close to the normal curve"
    )
    ax5.set_xlabel("Residuals")
    ax5.set_ylabel("Density")

    # ── 6. Blank panel ───────────────────────
    ax6 = fig.add_subplot(gs[2, 1])
    ax6.axis("off")

    # Final spacing
    fig.subplots_adjust(hspace=0.45)
    plt.show()

    return vif_df
```

```{python}
model_3 = sm.OLS(y, X_3).fit(cov_type="HC1")

plot_regression_diagnostics(model_3, X_3)
```

## England's energy crisis is no longer about volatility - its about persistence and inequality.

*Date: 12 Jan 2026*

While headline prices have eased since their 2022 peak, household energy bills in England remain far above pre-crisis levels and are projected to rise in 2026. What has emerged is not a short-lived shock, but a sustained financial strain that is unevenly distributed across households, housing types and places.

This persistence matters. When high energy costs endure, they stop being a temporary hardship and begin to shape household finances, housing affordability and regional inequality. Understanding who is most affected, and why, is central to designing effective energy policy that goes beyond short-term handouts and subsidies.

Using price cap data, household energy costs, income estimates and housing characteristics, we examine how sustained high energy prices are translating into financial stress — and why some households and places experience a greater burden than others.

### From shock to persistence

The sharp rise in energy bills in 2022 was driven by global wholesale gas prices and exacerbated by geopolitical shocks[^1]. Since then, wholesale prices have moderated, and the government’s Energy Price Guarantee (EPG) temporarily capped household exposure at the height of the crisis[^2].

[^1]: Russia-Ukraine War (<https://commonslibrary.parliament.uk/research-briefings/cbp-9714/>)

[^2]: In Sep 22, then-Prime Minister Elizabeth Truss announced the implementation of an Energy Price Guarantee (EPG) which meant that a typical UK household would pay up to £2,500 a year on their energy bill for the next two years. <https://www.gov.uk/government/news/government-announces-energy-price-guarantee-for-families-and-businesses-while-urgently-taking-action-to-reform-broken-energy-market>

Yet this has not returned bills to anything close to pre-2021 norms. Latest estimates suggest that the energy price cap remains around £600 (45%) higher than pre-crisis levels ([Figure 1]{.underline}), and is projected to rise by a further 3.2% in the coming quarters, due to structural increases in the cost of energy transmission[^3]. In other words, while volatility has eased, prices have settled at a historically high level.

[^3]: Cornwall Insight estimates (https://cornwall-insight.com/predictions-and-insights-into-the-default-tariff-cap/)

```{python}
#| label: Summary of data from Ofgem on the Energy Price Cap 
#| echo: false
#| warning: false
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import matplotlib.dates as mdates
import matplotlib.ticker as mticker

df = pd.read_csv(
    "data/energy_price_cap_2019_2025.csv",
    parse_dates=["period_start", "period_end"],
    dayfirst=True)

# keep from Oct 2021 onwards
df = df[df["period_start"] >= "2021-10-01"].copy()

# sort by start then end so "latest" definitions win if duplicated
df = df.sort_values(["period_start", "period_end"])

# if there are duplicate period_start dates, keep the last one
df = df.drop_duplicates(subset=["period_start"], keep="last").reset_index(drop=True)

# X: all start dates + final endpoint (forecast end)
x_step = list(df["period_start"])
x_step.append(df["period_end"].iloc[-1])  # extend to last period end

# Applied series: hold last value to the end
y_applied = df["cap_applied"].astype(float).tolist()
y_applied.append(y_applied[-1])

# Counterfactual: only show during EPG, otherwise NaN
y_cf = df["cap_level"].where(df["cap_type"].eq("EPG")).astype(float).tolist()
y_cf.append(y_cf[-1])  # hold last cf value (will be NaN if last isn't EPG)
```

```{python}
#| label: Figure 1 - Recent trends in energy prices
#| echo: false
#| warning: false
fig, ax = plt.subplots(figsize=(8, 5))

# Set time frame for Energy price Guarantee 
epg_start = pd.Timestamp("2022-10-01")
epg_end   = pd.Timestamp("2023-06-30")

# Build x-range for shading
x_epg = pd.to_datetime([
    epg_start,
    epg_end
])

# Shade from £0 to £2,500
ax.fill_between(
    x_epg,
    y1=0,
    y2=2500,
    step="post",
    color="#4b1f2a",
    alpha=0.08,
    zorder=0
)

ax.step(
    x_step, y_applied,
    where="post",
    color="#4b1f2a",
    linewidth=2.8,
    label="Price cap (applied)"
)

ax.step(
    x_step, y_cf,
    where="post",
    color="#a24d5f",
    linewidth=2.2,
    linestyle=":",
    label="Price cap (counterfactual)"
)
# Counterfactual values at boundaries
cf_oct22 = df.loc[df["period_start"] == epg_start, "cap_level"].iloc[0]
cf_jun23 = df.loc[df["period_start"] == pd.Timestamp("2023-04-01"), "cap_level"].iloc[0]

# Applied cap level during EPG
applied_epg = 2500

ax.vlines(
    epg_start,
    ymin=applied_epg,
    ymax=cf_oct22,
    colors="#a24d5f",
    linestyles=":",
    linewidth=2
)

ax.vlines(
    epg_end,
    ymin=applied_epg,
    ymax=cf_jun23,
    colors="#a24d5f",
    linestyles=":",
    linewidth=2
)

# Axes formatting
ax.set_xlim(pd.Timestamp("2021-10-01"), pd.Timestamp("2026-07-01"))
ax.set_ylim(0, 4500)
ax.yaxis.set_major_locator(mticker.MultipleLocator(1000))
ax.yaxis.set_major_formatter(lambda v, _: f"£{int(v):,}")

# ticks every 6 months (Apr & Oct)
ax.xaxis.set_major_locator(mdates.MonthLocator(bymonth=[4, 10]))
ax.xaxis.set_major_formatter(mdates.DateFormatter("%b %y"))
ax.tick_params(axis="x", labelsize=12)

ax.grid(axis="y", color="#dddddd", linewidth=0.8)
ax.grid(axis="x", visible=False)
ax.set_ylabel("Annual bill equivalent (£)", fontsize=12)

# Label the Price Cap line
ax.text(
    pd.Timestamp("2025-02-01"), 
    2000,
    "Price Cap",
    color="#4b1f2a",
    fontsize=12,
    fontweight="bold",
    va="center"
)

# Label the Energy Price Guarantee
ax.text(
    epg_start + pd.Timedelta(days=135),
    1600,
    "EPG active\n"
    "(set max prices\n"
    "Oct 22–Jun 23)",
    fontsize=10,
    ha="center",
    va="top",
    color="#4b1f2a"
)

# Label counterfactual price gap 
ax.text(
    pd.Timestamp("2023-05-01"),
    3550,
    "Price Cap\n"
    "(not implemented\n"
    "as above EPG)",
    fontsize=11,
    ha="left",
    va="bottom",
    color="#a24d5f"
)

# Label current levels 
ax.annotate(
    "Current \n= £1,755",
    xy=(pd.Timestamp("2025-10-01"), 1700),   # point TO line
    xytext=(pd.Timestamp("2025-10-01"), 1400),  # text BELOW
    ha="center",
    va="top",
    fontsize=11,
    color="#4b1f2a",
    arrowprops=dict(
        arrowstyle="-|>",
        color="#4b1f2a",
        linewidth=1.2
    )
)
# Label crisis jump 
ax.annotate(
    "Apr-22 \n54% increase",
    xy=(pd.Timestamp("2022-04-01"), 2000),   # point TO 
    xytext=(pd.Timestamp("2022-04-01"), 2500),  # text ABOVE
    ha="center",
    va="bottom",
    fontsize=11,
    color="#4b1f2a",
    arrowprops=dict(
        arrowstyle="-|>",
        color="#4b1f2a",
        linewidth=1.2
    )
)

# Mention projected increase
ax.annotate(
    "Proj 3.2%\nincrease in\nApr 26",
    xy=(pd.Timestamp("2026-04-01"), 1800),   
    xytext=(pd.Timestamp("2026-04-01"), 2200),  
    ha="center",
    va="bottom",
    fontsize=11,
    color="#4b1f2a",
    arrowprops=dict(
        arrowstyle="-|>",
        color="#4b1f2a",
        linewidth=1.2
    )
)

# Titles & caption
fig.suptitle(
    "The energy price cap has moderated slightly from the period of Energy Price\n"
    "Guarantee (EPG), but remains elevated relative to pre-crisis levels",
    x=0.01, y=0.95,
    ha="left",
    fontsize=14,
    fontweight="bold"
)

fig.text(
    0.01, -0.09,
    "Source: Ofgem, Cornwall Insights. The energy price cap is the maximum amount energy\n"
    "suppliers can charge households on a standard variable tariff. Price cap based on typical\n" 
    "household energy use.",
    fontsize=12,
    ha="left"
)

for spine in ["top", "left", "right"]:
    ax.spines[spine].set_visible(False)

plt.tight_layout()
plt.show()
```

Persistent high prices matter not just because they erode living standards, but because of how they feed into household finances. The average level of energy debt and the number of households in arrears have risen sharply since 2021, for both electricity and gas ([Figure 2]{.underline}). This pattern suggests that many households have been unable to fully absorb higher bills through short-term adjustments such as reducing consumption or drawing on savings. Instead, high energy costs are increasingly being managed through debt, deferred payments and arrears, a clear signal of financial stress rather than temporary inconvenience.

```{python}
#| label: Figure 2 - Average levels of energy debt and rising number of households in arrears
#| echo: false
#| warning: false
# Plot figures for energy debt 
# Consistent colour palette
COL_ELEC = "#4b1f2a"   # main dark
COL_GAS  = "#a24d5f"   # lighter accent

# Define helper function to clean columns from Ofgem data 
def parse_quarter(q):
    qtr, year = q.split()
    q_num = int(qtr.replace("Q", ""))
    
    # Map quarters to start months (Ofgem-style cadence)
    month_map = {1: 1, 2: 4, 3: 7, 4: 10}
    return pd.Timestamp(year=int(year), month=month_map[q_num], day=1)

# Load data 
def load_quarter_data(path):
    df = pd.read_csv(path)
    
    # Rename first column to something usable
    df = df.rename(columns={df.columns[0]: "quarter"})
    
    # Parse quarter-year to datetime
    df["date"] = df["quarter"].apply(parse_quarter)
    
    # Filter to Oct 2021 – Oct 2025
    df = df[
        (df["date"] >= "2021-10-01") &
        (df["date"] <= "2025-10-01")
    ].sort_values("date")
    
    return df

# Read CSV files 
df_debt = load_quarter_data(r"data/average-level-of-debt-norepay.csv")
df_arrears = load_quarter_data(r"data/number-of-accounts-in-arrears.csv")

fig, axes = plt.subplots(
    1, 2,
    figsize=(8, 5),
    sharey= False
)

def plot_panel(ax, df, title):
    ax.plot(
        df["date"],
        df["Electricity"],
        color=COL_ELEC,
        linewidth=2.5, 
        label="Electricity"
    )
    
    ax.plot(
        df["date"],
        df["Gas"],
        color=COL_GAS,
        linewidth=2.5,
        linestyle="--", 
        label="Gas"
    )
    
    ax.set_title(title, fontsize=12, loc="center")
    
    ax.grid(axis="y", color="#dddddd", linewidth=0.8, alpha=0.7)
    ax.grid(axis="x", visible=False)

    ax.legend(
        loc="upper right",
        frameon=False,
        fontsize=12,
        ncol=1
    )
    
    for spine in ["top", "right", "left"]:
        ax.spines[spine].set_visible(False)

# Plot data 
plot_panel(
    axes[0],
    df_debt,
    "Average level of debt\n(no repayment arrangement)"
)

plot_panel(
    axes[1],
    df_arrears,
    "Num. of accounts in arrears\n(no repayment arrangement)"
)

# Set figure axes 
for ax in axes:
    ax.set_xlim(pd.Timestamp("2021-10-01"), pd.Timestamp("2025-10-01"))
    ax.xaxis.set_major_locator(mdates.MonthLocator(bymonth=[4, 10]))
    ax.xaxis.set_major_formatter(mdates.DateFormatter("%b %y"))
    ax.tick_params(axis="x", labelrotation=30, labelsize=11, pad=5)
    ax.tick_params(axis="y", labelsize=12)
    ax.tick_params(axis="y", length=0)
    
# Left panel: £ values
axes[0].yaxis.set_major_formatter(lambda v, _: f"£{int(v):,}")
axes[0].set_ylim(500, 2100)
axes[0].set_yticks([500, 800, 1100, 1400, 1700, 2000])

# Right panel: counts
def k_m_formatter(x, pos):
    if x >= 1_000_000:
        return f"{x/1_000_000:.1f}M"
    elif x >= 1_000:
        return f"{int(x/1_000)}k"
    else:
        return str(int(x))

axes[1].yaxis.set_major_formatter(mticker.FuncFormatter(k_m_formatter))
axes[1].set_ylim(500_000, 1_300_000)
axes[1].set_yticks([500_000, 650_000,800_000,950_000,1_100_000,1_250_000])

# Set Figure title and source text 
fig.suptitle(
    "Average debt levels and no. of households in arrears are at an all-time high,\n"
    "suggesting that many households are unable to fully absorb higher costs through\n"
    "short-term adjustments alone.",
    x=0.01, y=0.96,
    ha="left",
    fontsize=14,
    fontweight="bold"
)

fig.text(
    0.01, -0.02,
    "Source: Ofgem data. Information accurate as of Dec 2025.",
    ha="left",
    fontsize=11
)

plt.tight_layout(rect=[0, 0, 1, 0.98])
plt.show()
```

These pressures extend well-beyond the poorest households. Data from the 2023/24 Family Resources Survey show that more than 15% of middle-income households report difficulty keeping their homes warm. Unsurprisingly, energy costs remain a major public concern. A March 2022 Ipsos survey found that nearly nine in ten people were worried about household energy prices, a figure that has remained stubbornly high ([Figure 3]{.underline}).

```{python}
#| label: Figure 3 - Sentiment data on energy burden
#| echo: false
#| warning: false
# Read CSV files 
df_frs = pd.read_csv(r"data/FRS_KeepWarm.csv")
df_ipsos = pd.read_csv(r"data/ipsos.csv")
df_frs = df_frs.rename(columns={"Proportion of families that cannot keep home adequately warm ": "Proportion"})

# Figure setup
fig, (ax1, ax2) = plt.subplots(
    1, 2,
    figsize=(8, 5),
    gridspec_kw={"width_ratios": [1.1, 1]}
)

fig.suptitle(
    "Higher energy costs are experienced by households across all incomes\n"
    "and remain a major public concern in England",
    x=0.01, y=0.97,
    ha="left",
    fontsize=14,
    fontweight="bold"
)

fig.text(
    0.26, 0.80,
    "More than 15% of middle-income households\nreported difficulty in keeping homes warm",
    ha="center",
    va="bottom",
    fontsize=13
)

fig.text(
    0.75, 0.80,
    "Close to 9 in 10 families surveyed reflect\nconcern over the price of energy",
    ha="center",
    va="bottom",
    fontsize=13
)

fig.text(
    0.01, 0.045,
    "Source: Family Resources Survey, 2023/24, Department for Work and Pensions; Ipsos UK",
    ha="left",
    fontsize=11
)

# LEFT PANEL — FRS (adjusted)
ax1.axhline(
    y=15,
    color="#7a7a7a",
    linestyle=":",
    linewidth=2,
    zorder=0
)

ax1.bar(
    df_frs["Decile"],
    df_frs["Proportion"] * 100,
    color="#4b1f2a"
)

ax1.set_ylabel("Proportion of households (%)", fontsize=12)

ax1.set_ylim(0, 23.5)
ax1.set_yticks(np.arange(0, 25, 5))

ax1.set_xticks(range(1, 11))
ax1.set_xticklabels(
    ["Lowest\nincome\ndecile", "2", "3", "4", "5", "6", "7", "8", "9", "Highest\nincome\ndecile"],
    fontsize=9
)

ax1.tick_params(axis="y", labelsize=10)

ax1.grid(axis="y", visible=False)
ax1.grid(axis="x", visible=False)
ax1.set_axisbelow(True)

ax1.spines["top"].set_visible(False)
ax1.spines["right"].set_visible(False)
ax1.spines["left"].set_visible(False)
ax1.spines["bottom"].set_color("#bdbdbd")
ax1.spines["bottom"].set_linewidth(0.8)

# RIGHT PANEL — Ipsos Survey findings
periods = df_ipsos["Period"]

very = df_ipsos["Proportion_very_concerned"] * 100
somewhat = df_ipsos["Proportion_somewhat_concerned"] * 100
neutral = df_ipsos["Proportion_neutral"] * 100
not_concerned = df_ipsos["Proportion_not_concerned"] * 100

y = np.arange(len(periods))
bar_h = 0.62

ax2.barh(y, very, height=bar_h, color="#c95c78", label="Very concerned")
ax2.barh(y, somewhat, left=very, height=bar_h, color="#efb4c2", label="Fairly concerned")
ax2.barh(y, neutral, left=very + somewhat, height=bar_h, color="#dfeeee")
ax2.barh(y, not_concerned, left=very + somewhat + neutral,
         height=bar_h, color="#9ec7c3", label="Not concerned")

for i in range(len(y)):

    # Skip labels for Mar-21
    if periods.iloc[i].strip() == "Mar-21":
        continue
    ax2.text(
        very[i] / 2, y[i], f"{int(very[i])}%",
        ha="center", va="center",
        fontsize=11, color="white", fontweight="bold"
    )
    ax2.text(
        very[i] + somewhat[i] / 2, y[i], f"{int(somewhat[i])}%",
        ha="center", va="center",
        fontsize=11, color="#333333", fontweight="bold"
    )
    ax2.text(
        very[i] + somewhat[i] + neutral[i] + not_concerned[i] / 2,
        y[i], f"{int(not_concerned[i])}%",
        ha="center", va="center",
        fontsize=11, color="#2f4f4f", fontweight="bold"
    )

ax2.set_yticks(y)
ax2.set_yticklabels(periods, fontsize=10)
ax2.invert_yaxis()

# Visually hide the "Mar-21" y-axis label
for label in ax2.get_yticklabels():
    if label.get_text().strip() == "Mar-21":
        label.set_color("white")

ax2.set_xlim(0, 100)
ax2.set_xlabel("Share of respondents (%)", fontsize=12)

ax2.grid(axis="x", visible=False)
ax2.grid(axis="y", visible=False)
ax2.set_axisbelow(True)

ax2.spines["top"].set_visible(False)
ax2.spines["right"].set_visible(False)
ax2.spines["left"].set_visible(False)
ax2.spines["bottom"].set_color("#bdbdbd")
ax2.spines["left"].set_linewidth(0.8)
ax2.spines["bottom"].set_linewidth(0.8)

handles, labels = ax2.get_legend_handles_labels()
fig.legend(
    handles,
    labels,
    loc="upper right",
    bbox_to_anchor=(0.965, 0.78),  # figure coordinates
    ncol=2,
    frameon=False,
    fontsize=11,
    handlelength=1.5
)

# Final layout 
plt.tight_layout(rect=[0, 0.06, 1, 0.99])
plt.show()
```

### Uneven geography of housing energy burden

However, this strain is not evenly distributed. Although energy prices are set nationally, their impact is far from uniform across England. [Figure 4]{.underline} shows how the energy burden — defined as household energy costs as a share of income after housing costs — is higher in many parts of the North and West, and lower across much of the South and East.

This pattern mirrors broader inequalities in income and housing conditions, but also reflects differences in the energy efficiency of the housing stock. If energy prices are broadly similar across England, these geographic differences in energy burden point to deeper structural drivers.

```{python}
#| label: Figure 4 - Geographical distribution of Energy Burden 
#| echo: false
#| warning: false
import matplotlib.pyplot as plt
import matplotlib as mpl
from matplotlib.colors import ListedColormap, BoundaryNorm
from matplotlib_scalebar.scalebar import ScaleBar
from mpl_toolkits.axes_grid1.inset_locator import inset_axes
from matplotlib.patches import Circle
import matplotlib.patheffects as pe

# Colour map & bins
colors = ["#f7efe7", "#efc7b0", "#d88c73", "#a24d5f", "#4b1f2a"]
colors_rgba = [mpl.colors.to_rgba(c, alpha=0.85) for c in colors]
cmap = ListedColormap(colors_rgba)

bins = [0.0, 0.035, 0.045, 0.055, 0.065, msoa_gdf_merged["energy_burden"].max()]
norm = BoundaryNorm(bins, ncolors=cmap.N)

# Figure
fig, ax = plt.subplots(figsize=(8, 9))

# Plot scotland area 
scotland_clip.plot(
    ax=ax,
    color="#e4e4e4",
    linewidth=0,
    zorder=0)

# Wales + NA MSOAs (grey)
msoa_gdf.loc[
    ~msoa_gdf["MSOA_code"].str.startswith("E")
].plot(ax=ax, color="#e4e4e4", linewidth=0, zorder=1)

msoa_gdf_merged.loc[
    msoa_gdf_merged["energy_burden"].isna()
].plot(ax=ax, color="#e4e4e4", linewidth=0, zorder=1)

# England MSOAs (data)
msoa_gdf_merged.loc[
    msoa_gdf_merged["energy_burden"].notna()
].plot(
    column="energy_burden",
    ax=ax,
    cmap=cmap,
    norm=norm,
    linewidth=0,
    zorder=2
)

# Region boundaries & coastline
region_gdf.boundary.plot(
    ax=ax,
    linewidth=1,
    edgecolor="#2b2b2b",
    alpha=0.95,
    zorder=3
)

msoa_gdf.loc[
    msoa_gdf["MSOA_code"].str.startswith("E")
].dissolve().boundary.plot(
    ax=ax,
    linewidth=0.6,
    edgecolor="#2b2b2b",
    zorder=4
)

# City markers
cities_gdf.plot(
    ax=ax,
    color="white",
    edgecolor="black",
    linewidth=0.6,
    markersize=35,
    zorder=6
)

# City labels (with white halo)
for _, row in cities_gdf.iterrows():
    ax.text(
        row.geometry.x + 6000,
        row.geometry.y + 6000,
        row["city"],
        fontsize=10,
        color="black",
        zorder=7,
        path_effects=[
            pe.withStroke(linewidth=3, foreground="white")
        ]
    )

# London inset (TOP RIGHT)
london_msoa = gpd.overlay(msoa_gdf_merged, gla, how="intersection",
    keep_geom_type=False)

axins = ax.inset_axes(
    [0.76, 0.66, 0.28, 0.28],   
    transform=ax.transAxes
)

for spine in axins.spines.values():
    spine.set_linewidth(1.2)
    spine.set_edgecolor("black")

london_msoa[london_msoa["energy_burden"].isna()].plot(
    ax=axins, color="#e4e4e4", linewidth=0
)

london_msoa[london_msoa["energy_burden"].notna()].plot(
    column="energy_burden",
    ax=axins,
    cmap=cmap,
    norm=norm,
    linewidth=0
)

LA.boundary.plot(
    ax=axins,
    linewidth=0.3,
    edgecolor="black",
    zorder=3
)

gla.boundary.plot(
    ax=axins,
    linewidth=1.2,
    edgecolor="black"
)
axins.set_xticks([])
axins.set_yticks([])
axins.set_aspect("equal")
axins.text(
    0.5, -0.05,
    "London",
    transform=axins.transAxes,
    ha="center",
    va="top",
    fontsize=12,
    fontweight="bold"
)

# Colour bar (BOTTOM RIGHT)
cax = fig.add_axes([0.56, 0.08, 0.37, 0.022])

cbar = mpl.colorbar.ColorbarBase(
    cax,
    cmap=cmap,
    norm=norm,
    orientation="horizontal",
    ticks=[0.00, 0.035, 0.045, 0.055, 0.065, 0.12]
)

# Tick labels (including extremes)
cbar.ax.set_xticklabels(
    ["0%", "3.5%", "4.5%", "5.5%", "6.5%", "12%"],
    fontsize=12
)

# Move label ABOVE the bar
cbar.set_label(
    "% household income spent on energy",
    fontsize=13,
    fontweight="bold",
    labelpad= 8
)
cbar.ax.xaxis.set_label_position("top")

# Titles & caption
fig.suptitle(
    "Energy burden varies substantially across England, with households in \n"
    "parts of the North and West spending a higher share of income on energy.",
    x=0.01, y=0.95,
    ha="left",
    fontsize=16,
    fontweight="bold"
)

fig.text(
    0.01, -0.05,
    "Notes: Energy burden is defined as annual household expenditure on gas and electricity divided\n"
    "by median after-housing-cost income at MSOA-level. Energy consumption is based on DESNZ\n"
    "sub-national gas and electricity statistics; prices follow Ofgem default tariff caps. Income data\n"
    "are derived from ONS small-area estimates. MSOAs with insufficient records and areas outside\n"
    "England are shown in grey.",
    fontsize=12,
    ha="left"
)

fig.subplots_adjust(top=0.90)
ax.axis("off")
plt.show()
```

### What drives energy burden: household income and housing quality

[Figure 5]{.underline} unpacks two of the strongest patterns that emerge from the data: energy burden falls as incomes rise, and increases as housing becomes less energy efficient. But are these relationships simply reflecting regional or urban–rural differences?

```{python}
#| label: Figure 5 - Distribution of energy burden across income and energy deciles 
#| echo: false
#| warning: false
msoa_agg = msoa_agg.copy()

msoa_agg["income_decile"] = pd.qcut(
    msoa_agg["income_10k"],
    10,
    labels=range(1, 11)
)

msoa_agg["epc_dg_decile"] = pd.qcut(
    msoa_agg["share_epc_DG"],
    10,
    labels=range(1, 11)
)

# Write helper function to compute median, 25th and 75th percentile of values for MSOAs 
def summarise_energy_burden(df, decile_col):
    return (
        df.groupby(decile_col)["energy_burden"]
          .agg(
              median="median",
              p25=lambda x: np.percentile(x, 25),
              p75=lambda x: np.percentile(x, 75)
          )
          .reset_index()
    )

income_summary = summarise_energy_burden(msoa_agg, "income_decile")
epc_summary    = summarise_energy_burden(msoa_agg, "epc_dg_decile")
```

```{python}
#| label: Figure 5 - Distribution of energy burden across income and energy deciles (2) 
#| echo: false
#| warning: false
COL_MAIN = "#4b1f2a"

fig, axes = plt.subplots(
    1, 2,
    figsize=(8, 5),
    sharey=True
)

def plot_decile_panel(ax, df, title):
    x = df.iloc[:, 0].astype(int)
    
    # IQR
    ax.vlines(
    x,
    df["p25"],
    df["p75"],
    color=COL_MAIN,
    alpha=0.5,     
    linewidth=2     
)
    
    # Median
    ax.scatter(
    x,
    df["median"],
    color=COL_MAIN,
    s=60,                 # ↑ from 40
    zorder=3,
    edgecolor="white",
    linewidth=0.8
)
    
    ax.set_title(
    title,
    fontsize=13,
    fontweight="bold",
    loc="center",
    pad=6
)
    
    ax.grid(axis="y", color="#dddddd", linewidth=0.8, alpha = 0.8)
    ax.grid(axis="x", visible=False)
    
    for spine in ["top", "right", "left"]:
        ax.spines[spine].set_visible(False)
    
    ax.tick_params(axis="y", length=0)
    ax.tick_params(axis="x", labelsize=11)

plot_decile_panel(
    axes[0],
    income_summary,
    "Household Incomes"
)

plot_decile_panel(
    axes[1],
    epc_summary,
    "Share of poor EPC homes (D-G)"
)

axes[0].set_ylabel("Energy burden (% of income)", fontsize=12)

for ax in axes:
    ax.set_xticks(range(1, 11))
    ax.set_xlabel("Decile (1 = lowest)", fontsize=12)

axes[0].set_ylim(0.035, 0.088)
axes[0].set_yticks([0.04, 0.05, 0.06, 0.07, 0.08])
axes[0].yaxis.set_major_formatter(lambda v, _: f"{int(v*100)}%")

axes[0].text(
    0.5, 1,
    "Energy burden falls by ≈2 p.p. between\n"
    "lowest and highest income deciles",
    transform=axes[0].transAxes,
    ha="center",
    va="top",
    fontsize=12,
    color=COL_MAIN
)

axes[1].text(
    0.5, 1,
    "Energy burden increases by ≈0.7 p.p.\n"
    "from lowest to highest decile\n"
    "of housing inefficiency",
    transform=axes[1].transAxes,
    ha="center",
    va="top",
    fontsize=12,
    color=COL_MAIN
)


fig.suptitle(
    "Energy burden is felt most accutely by households with lower incomes and\n"
    "poorer housing energy efficiency",
    x=0.01, y=0.95,
    ha="left",
    fontsize=14,
    fontweight="bold"
)

fig.text(
    0.01, -0.09,
    "Notes: MSOAs grouped into national deciles by income and by share of EPC D–G homes.\n"
    "Points show median energy burden; vertical lines show interquartile range.\n"
    "Source: Ofgem EPC data, income estimates, and modelled household energy costs.",
    ha="left",
    fontsize=11
)

plt.tight_layout(rect=[0, 0, 1, 0.98])
plt.show()
```

To investigate this, we ran a multivariate model that accounts simultaneously for income, housing characteristics, tenure, heating type and region. A summary of findings are as follows:

1.  [Household income is the strongest driver]{.underline}. Holding housing quality and location constant, a **10% increase in income is associated with a 0.5 percentage-point reduction in energy burde**n. The effect is largest at the lower end of the income distribution, indicating that modest income gains can substantially reduce energy stress for lower-income households.
2.  [Energy efficiency of housing also plays an independent role]{.underline}. After accounting for income and region, **a** **10 percentage-point increase in the share of poorly insulated homes (EPC D–G) is associated with a 0.14 percentage-point increase in energy burden**. Areas with a high concentration of inefficient housing face systematically higher energy costs relative to income, regardless of who lives there.
3.  [Tenure compounds these effects]{.underline}. Areas with a **higher share of private renting experience higher energy burdens**, reflecting the limited agency of renters to improve energy efficiency. By contrast, greater uptake of renewable heating technologies is associated with lower energy burdens, highlighting the potential of structural interventions to reduce long-term exposure to high prices.

After accounting for these factors, regional differences become relatively small. Geography matters primarily because of who lives where and in what kind of housing.

### Going forward: Implications for energy policy

These findings suggest that policies focused solely on suppressing prices or providing blanket support risk missing the structural drivers of energy vulnerability.

First, the persistence of elevated energy burden into the middle of the income distribution strengthens the case for income-based support mechanisms, such as a social tariff, that better reflect households’ ability to pay rather than relying on blunt eligibility thresholds, which may result in cliff-effects.

Second, the strong relationship between housing efficiency and energy burden reiterates the importance of long-term investment in energy efficiency, particularly in areas with a high concentration of poorly insulated homes. Improving the efficiency of the housing stock and investing in renewable, where possible, offers a durable way to reduce bills, rather than repeatedly offsetting them through subsidies.

Finally, these issues are particularly acute for private renters, who are more likely to live in inefficient properties but have limited control over energy upgrades. Strengthening minimum efficiency standards and protections for renters could play a key role in reducing exposure to high energy costs, especially among the vulnerable that rent privately.

# Technical Appendix

{{< pagebreak >}}

## References

```{python}
msoa_agg["log_income"] = np.log(msoa_agg["income_10k"])
msoa_agg["log_energy_burden"] = np.log(msoa_agg["energy_burden"])
msoa_agg["log_annual_energy_cost"] = np.log(msoa_agg["annual_energy_cost"])

reg_df3 = msoa_agg[["log_energy_burden", "energy_burden", "log_income", "share_epc_DG", "median_floor_area_m2", "private_rented_census", "share_renewable_heating", "share_not_grid", "Ruralurban", "annual_energy_cost", "log_annual_energy_cost", "share_detached"]]

reg_df3["urban_dummy"] = (
    reg_df3["Ruralurban"]
    .map({"Urban": 1, "Rural": 0})
)

X_4 = reg_df3[["share_epc_DG", "median_floor_area_m2", "private_rented_census", "share_not_grid", "log_income", "share_detached"]]
X_4 = sm.add_constant(X_4)

X_5 = reg_df3[["share_epc_DG", "median_floor_area_m2", "private_rented_census", "share_not_grid", "log_income", "share_detached", "urban_dummy"]]
X_5 = sm.add_constant(X_5)

X_6 = pd.concat([reg_df3[["share_epc_DG", "median_floor_area_m2", "private_rented_census", "share_not_grid", "log_income", "share_detached", "urban_dummy"]], region_dummies], axis = 1)
X_6 = sm.add_constant(X_6)
X_6 = X_6.astype(float)

y = reg_df3["annual_energy_cost"]

model_4 = sm.OLS(y, X_4).fit(cov_type="HC1")  # robust SEs
print(model_4.summary())
model_5 = sm.OLS(y, X_5).fit(cov_type="HC1")  # robust SEs
print(model_5.summary())
model_6 = sm.OLS(y, X_6).fit(cov_type="HC1")  # robust SEs
print(model_6.summary())

results_table = summary_col(
    results=[model_4, model_5, model_6],
    model_names=['Base_Model', "Rural/Urban", "RegionFE"],
    stars=True,
    float_format="%0.3f",
    # You can customize what model statistics show up here (like R2, N, F-stat)
    info_dict={'N':lambda x: "{0:d}".format(int(x.nobs))}
)

# # Round for readability
print(results_table)

plot_regression_diagnostics(model_6, X_6)
```

```{python}
#| echo: false
#| warning: false
# Exploratory Analysis - Checking the relationships between the variables and energy burden 
# Select variables for plotting
plot_df = msoa_agg[["log_income", "median_floor_area_m2", "mean_epc_score", "share_epc_DG", "private_rented_census", "share_renewable_heating", "share_not_grid", "annual_energy_cost", "share_detached", "share_flats_purpose_built"]].dropna()

# Convert to long format
long_df = pd.melt(
    plot_df,
    id_vars=["annual_energy_cost"],
    var_name="predictor",
    value_name="x_value"
)

axis_labels = {
    "log_income": "Log Disposable income ('000) \naft housing costs)",
    "median_floor_area_m2": "Median floor area (m²)",
    "mean_epc_score": "Mean EPC energy efficiency score",
    "share_epc_DG" : "Share of Buildings with EPC D-G",
    "private_rented_census": "Share of households \nprivate renting",
    "share_renewable_heating": "Share of households with \nrenewable-only heating",
    "share_not_grid": "Share of households \nnot on the gas grid",
    "share_detached" : "Share of detached houses" ,
    "share_flats_purpose_built" : "Share of flats"
}

predictors = long_df["predictor"].unique()

cols = 3
rows = (len(predictors) + cols - 1) // cols

fig, axes = plt.subplots(rows, cols, figsize=(9, 3 * rows))
axes = axes.flatten()

for i, predictor in enumerate(predictors):
    subset = long_df[long_df["predictor"] == predictor]

    sns.regplot(
        data=subset,
        x="x_value",
        y="annual_energy_cost",
        scatter_kws={
            "alpha": 0.3,
            "s": 10,
            "color": "steelblue"
        },
        line_kws={
            "color": "black",
            "linewidth": 1.5
        },
        ci=None,
        ax=axes[i]
    )

    axes[i].set_title(f"Energy Cost vs \n{axis_labels[predictor]}")
    axes[i].set_xlabel(axis_labels[predictor])
    axes[i].set_ylabel("Energy Cost")

# Remove unused axes
for j in range(i + 1, len(axes)):
    fig.delaxes(axes[j])

plt.tight_layout()
plt.suptitle(
    "Bivariate relationships between Energy Cost and key predictors",
    y=1.02,
    fontsize=14
)

sns.despine()
plt.show()

```

```{python}
from libpysal.weights import Queen
import geopandas as gpd

# Load your spatial data (shapefile or GeoJSON)
gdf = msoa_valid

# Create the spatial weights matrix
w = Queen.from_dataframe(gdf)
w.transform = 'r'  # Row-standardize (averages the impact of neighbors)
```

```{python}
from esda.moran import Moran

ols_resid = model_6.resid
mi = Moran(ols_resid, w)

print(mi.I, mi.p_sim)
```

```{python}
import numpy as np
import statsmodels.api as sm
from spreg import ML_Lag, ML_Error

# Dependent variable (n x 1)
y_sp = reg_df["energy_burden"].values.reshape(-1, 1)

# Independent variables (n x k) — NO constant
X_sp = reg_df[
    [
        "log_income",
        "share_epc_DG",
        "median_floor_area_m2_capped",
        "private_rented_census",
        "share_renewable_heating",
        "share_not_grid",
    ]
].values

w.transform = "r"

sar_model = ML_Lag(
    y_sp,
    X_sp,
    w=w,
    name_y="energy_burden",
    name_x=[
        "log_income",
        "share_epc_DG",
        "median_floor_area_m2_capped",
        "private_rented_census",
        "share_renewable_heating",
        "share_not_grid",
    ],
)

print(sar_model.summary)
```

```{python}
sem_model = ML_Error(
    y_sp,
    X_sp,
    w=w,
    name_y="energy_burden",
    name_x=[
        "log_income",
        "share_epc_DG",
        "median_floor_area_m2_capped",
        "private_rented_census",
        "share_renewable_heating",
        "share_not_grid",
    ],
)

print(sem_model.summary)
```

```{python}
print("OLS AIC:", ols_model.aic)
print("SAR AIC:", sar_model.aic)
print("SEM AIC:", sem_model.aic)
```

```{python}
from esda.moran import Moran
mi_sem = Moran(sem_model.u, w)
print(mi_sem.I, mi_sem.p_sim)
```

```{python}
sdm_model = ML_Lag(
    y_sp,
    X_sp,
    w=w,
    slx_lags=1,
    name_y="energy_burden",
    name_x=[
        "log_income",
        "share_epc_DG",
        "median_floor_area_m2_capped",
        "private_rented_census",
        "share_renewable_heating",
        "share_not_grid",
    ],
)

print(sdm_model.summary)
```

```{python}
mi_sdm = Moran(sdm_model.u, w)
print(mi_sdm.I, mi_sdm.p_sim)
```